{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Tone Classifier - CNN vs Fox News\n",
    "\n",
    "### About the project\n",
    "\n",
    "As per Pew Research Center, there are certain news outlets that are favorites amongst conservatives and liberals [1]. In this project, I aim to categorise **whether there exists a certian tone or sentiment** in the videos posted by these news outlets that make it a constant source of information for certain types of viewers. \n",
    "\n",
    "### Research Questions\n",
    "\n",
    "* Does there exist a certain tone or sentiment in the videos, which make it easily differentiable from other news outlets?\n",
    "* Based on above tone, can we build a supervised classifer model to distinguish content between CNN and Fox News?\n",
    "* What are the most common terms or words used in each of the news outlets and the associated sentiments?\n",
    "* Is there a common sentiment (positive, nnegative, neutral) for each of these channel outlets?\n",
    "\n",
    "### Dataset Description\n",
    "\n",
    "For this project, we generate our own dataset using the `YouTubeDataApi` where we extract 4000 videos from the most (`Fox News`) and least conservative channels (`CNN`) as per the Pew Research [1]. Following this, we download the transcript for all these videos (total 8000) using the `YouTubeTranscriptAPi`. The data contains 4000 videos from each of the channels and I believe that collecting this data directly from YouTube would help us accurately describe the common terms and sentiments as this news is presented on their channels. This also helps us download transcripts to define an underlying tone. The collected fields are described below: \n",
    "\n",
    "#### Data Glossary (collected data)\n",
    "\n",
    "1. `channel_name` - The name of the channel that the video was posted by, which may be an individual contributor or a group\n",
    "2. `video_id` - Unique identifier of the video in YouTube\n",
    "3. `video_title` - Title of the posted video\n",
    "4. `video_description` - Description of the posted video\n",
    "5. `video_published_at` - Time of the posting of video\n",
    "6. `video_view_count` - The number of views that the video received, at the itme of collection\n",
    "7. `video_like_count` - The number of likes that the video received, at the time of collection\n",
    "8. `video_comment_count` - The number of comments that the video received, at the time of collection\n",
    "9. `transcript` - The transcript of the entire video, pulled using the `video_id`\n",
    "11. `transcript_vader` - The polarity score of the transcript after applying `Vader` sentiment analyzer\n",
    "12. `vader_category` - The category calculated from the vader score, where \n",
    "\n",
    "### Suitability of algorithms\n",
    "\n",
    "* `AutoKeras` - The input type for this algorithm is very flexible, and the algorithm is super flexible with an easy to use interface for the task, backed by the power of TensorFlow [2].\n",
    "* `SVC` - We use this to compare with `AutoKeras`, as well as it's effectiveness in high-dimensional spaces which exist when we convert the transcript data into numerical using the `TfidfVectorizer` and because based on the above classifier, there exists a clear seperation between the two channels. We also notice that the number of dimensions are more than the number of samples which makes it a suitable data for `SVC`[3].\n",
    "\n",
    "### Approach\n",
    "\n",
    "This is being approached as a **binary** classification problem, where we input the `transcript` as the predictor (X) and we aim to predict the `channel_name` as the outcome (Y). We will apply various algorithms like AutoKeras (built on top of Tensorflow) and Support Vector Classifier (SVC) for this task and compare the performance of these algorithms. \n",
    "\n",
    "The chronological approach is as below - \n",
    "\n",
    "1. Importing Required Libraries\n",
    "2. Downloading the metrics and video information for each of the channels (`CNN`, `Fox News`)\n",
    "3. Downloading the transcript of each of the videos\n",
    "4. Exploratory Data Analysis for the downloaded data\n",
    "5. Data Cleaning\n",
    "6. Applying the `Vader` sentiment analyser on the transcripts to understand the common tone of these channels\n",
    "7. Applying the `AutoKeras` and `SVC` classifiers on the transcript data to predict the channel and printng the results\n",
    "8. Visualizing the results\n",
    "\n",
    "### Challenges\n",
    "\n",
    "* The `YouTubeDataAPI` only allows 10000 requests per day, and this limits the amount of data that we could collect and while the f-1 scores we have received are satisfactory, it would be interesting to note if the f-1 score changes in any way due to the dataset size\n",
    "* Transcripts are not available for a lot of videos for the channel `CNN` which causes a class imbalance. While this does impact the accuracy in some way, we use the f-1 score as an alternative measure to accuracy but the class imbalance cannot be completely ignored however because there is an external dependency in downloading the transcripts, there is not much that we can do in that regards. A solution is to undersample the `Fox News` videos to account for the imbalance but that would lead to loss of critical information hence that is not done in the below code. \n",
    "* The code - especially the transcript download - takes a long time which limits our ability to increase the size of the dataset exponentially without causing unreasonable run times for the code.\n",
    "\n",
    "### How does machine learning solve the problem?\n",
    "\n",
    "* In the below classifier, we have used different ML algorithms to determine a common tone, sentiment or set of words across different video transcripts to determine whether the video may have been posted by CNN or Fox News. By doing so, we are able to prove that there is a common and identifiable trend between the content of videos posted by these channels, and identifying this gives us the ability to classify the transcript to the given channel, with an accuracy of **>90%**\n",
    "* While the problem was limited to `CNN` and `Fox News`, the objective of this research goes deeoper into how certain news outlets employ certain techniques including a distinguishable tone and language to keep their viewers hooked, while presenting the same content as some of it's counterparts. This helps us in understanding how the same message can be delivered in different methods and can attract different set of audiences.\n",
    "* As a society, it also helps to know about these distingushable trends and in understanding which news agencies are using emotions (positive,negative) in their reporting to attract viewers to present a subject (news (world affairs)) which should ideally be neutral, but as defined is not.\n",
    "\n",
    "#### Risks\n",
    "\n",
    "* Currently the model has only been trained on less than 4000 videos per channel, and only for two channels. Hence, to accurately use and represent trends in the real world, we'd require the model to be trained on more volume and diversity of data.\n",
    "* Some of these trends may be subject to confidentiality and may be subject to approval by the owners of thsi content (news agencies) for larger scale analysis\n",
    "* If the model does not perform well, it will falsely classify a video to a different channel and if expanded to other news agencies, it may reduce the reliability of the reporting being falsely classified as news from a lower-reputed outlet.\n",
    "\n",
    "#### Advantages\n",
    "* Greater understanding of how news agencies employ techniques of introducing polarity in their reporting to attract viewership\n",
    "* An ability to expand to be able to identify a piece of content or video and map it to the reliability based on it's news channel classification. Example - CNN in our research was found to be more neutral so it's reliability could be considered more than Fox, which may be polarising it's content.\n",
    "\n",
    "\n",
    "### Future Work\n",
    "* Expanding this analysis to more news channels on both ends of the spectrum, and finding ways to avoid the class imbalance that we encountered earlier.\n",
    "* By doing above, we will make this into a multivariate classification problem which will be more difficult to train and evaluate\n",
    "\n",
    "\n",
    "References - \n",
    "\n",
    "1. https://www.pewresearch.org/journalism/2014/10/21/section-1-media-sources-distinct-favorites-emerge-on-the-left-and-right/\n",
    "2. https://autokeras.com/tutorial/text_classification/#\n",
    "3. https://towardsdatascience.com/everything-about-svm-classification-above-and-beyond-cc665bfd993e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G1Vw4__kYQUR",
    "outputId": "bb0289b6-9f45-4bc5-dd88-e86c27364881"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mahirjain/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mahirjain/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/mahirjain/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Required Libraries and necessary setup\n",
    "!pip install --upgrade google-api-python-client youtube-transcript-api autokeras --quiet\n",
    "!pip install vaderSentiment --quiet\n",
    "!pip install empath --quiet\n",
    "\n",
    "import json\n",
    "import googleapiclient\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import googleapiclient.discovery\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from autokeras import TextRegressor\n",
    "import string\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import empath\n",
    "\n",
    "# Download NLTK resources (if not already downloaded)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "q9o7kt4eYgu5"
   },
   "outputs": [],
   "source": [
    "#API_KEY = <INSERT_API_KEY>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XIHg9ppRY1My"
   },
   "outputs": [],
   "source": [
    "# youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcript & Videos Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XO-gQ5mLY51r",
    "outputId": "7bfa1530-5705-4058-e293-5bbad5b8346e"
   },
   "outputs": [],
   "source": [
    "# Video & Metrics collection from YouTube\n",
    "\n",
    "def download_statistics(username, limit=10, api_key=None):\n",
    "\n",
    "    # request = youtube.channels().list(\n",
    "    # part=\"contentDetails\",\n",
    "    # forUsername=username\n",
    "    # )\n",
    "\n",
    "    request = youtube.channels().list(\n",
    "    part=\"contentDetails\",\n",
    "    id=username\n",
    "    )\n",
    "\n",
    "    res = request.execute()\n",
    "    uploads_playlist_id = res[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
    "    videos_info = []\n",
    "\n",
    "    request = youtube.playlistItems().list(\n",
    "        part=\"snippet\",\n",
    "        playlistId = uploads_playlist_id\n",
    "        # YOUR SOLUTION\n",
    "    )\n",
    "\n",
    "    res = request.execute()\n",
    "\n",
    "    page_token = res['nextPageToken'] if res['nextPageToken'] else \"\"\n",
    "    for v in res[\"items\"]:\n",
    "        video_id = v['snippet']['resourceId']['videoId']\n",
    "        # Get video views count\n",
    "        stats_request = youtube.videos().list(\n",
    "            part=\"statistics\",\n",
    "            id=video_id\n",
    "        )\n",
    "        stats_res = stats_request.execute()\n",
    "\n",
    "        # Check if statistics are available for the video\n",
    "        try:\n",
    "            statistics = stats_res['items'][0]['statistics']\n",
    "            #print(statistics)\n",
    "            view_count = int(statistics['viewCount'])\n",
    "            like_count = int(statistics['likeCount'])\n",
    "            comment_count = int(statistics['commentCount'])\n",
    "        except Exception as e:\n",
    "            view_count = like_count = comment_count = 0\n",
    "\n",
    "        dict_vid = {\n",
    "            'channel_name': v['snippet']['channelTitle'],\n",
    "            'channel_id': v['snippet']['channelId'],\n",
    "            'video_id': video_id,\n",
    "            'video_title': v['snippet']['title'],\n",
    "            'video_description': v['snippet']['description'],\n",
    "            'video_published_at': v['snippet']['publishedAt'],\n",
    "            'video_view_count': view_count,\n",
    "            'video_like_count': like_count,\n",
    "            'video_comment_count': comment_count\n",
    "        }\n",
    "        videos_info.append(dict_vid)\n",
    "\n",
    "    while page_token and len(videos_info) < limit: # Limiting the number of API calls using the videos_info as the daily limit is exceeding otherwise\n",
    "        request = youtube.playlistItems().list(\n",
    "        part=\"snippet\",\n",
    "        playlistId = uploads_playlist_id,\n",
    "        pageToken = page_token\n",
    "    )\n",
    "        res = request.execute()\n",
    "        page_token = res['nextPageToken'] if res['nextPageToken'] else \"\"\n",
    "\n",
    "        for v in res[\"items\"]:\n",
    "            video_id = v['snippet']['resourceId']['videoId']\n",
    "\n",
    "            # Get video video views count\n",
    "            stats_request = youtube.videos().list(\n",
    "                part=\"statistics\",\n",
    "                id=video_id\n",
    "            )\n",
    "            stats_res = stats_request.execute()\n",
    "\n",
    "            # Check if statistics are available for the video\n",
    "            try:\n",
    "                statistics = stats_res['items'][0]['statistics']\n",
    "                #print(statistics)\n",
    "                view_count = int(statistics['viewCount'])\n",
    "                like_count = int(statistics['likeCount'])\n",
    "                comment_count = int(statistics['commentCount'])\n",
    "            except Exception as e:\n",
    "                view_count = like_count = comment_count = 0\n",
    "\n",
    "            dict_vid = {\n",
    "                'channel_name': v['snippet']['channelTitle'],\n",
    "                'channel_id': v['snippet']['channelId'],\n",
    "                'video_id': video_id,\n",
    "                'video_title': v['snippet']['title'],\n",
    "                'video_description': v['snippet']['description'],\n",
    "                'video_published_at': v['snippet']['publishedAt'],\n",
    "                'video_view_count': view_count,\n",
    "                'video_like_count': like_count,\n",
    "                'video_comment_count': comment_count\n",
    "            }\n",
    "            videos_info.append(dict_vid)\n",
    "    print(f\"The videos extracted from {youtube_id_1[username]} are: \", len(videos_info))\n",
    "    return videos_info\n",
    "\n",
    "\n",
    "#API_KEY = API_KEY\n",
    "\n",
    "youtube_id_1 = {\n",
    "     \"UCupvZG-5ko_eiXAupbDfxWw\" : \"CNN\",\n",
    "     \"UCXIJgqnII2ZOINSWNOGFThA\": \"Fox News\"\n",
    "}\n",
    "export_data = []\n",
    "\n",
    "# try:\n",
    "#     for id in youtube_id_1.keys():\n",
    "#         export_data.extend(download_statistics(id, limit=4000, api_key=API_KEY))\n",
    "# except Exception as e:\n",
    "#     print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_htaexDsZKlF"
   },
   "outputs": [],
   "source": [
    "# current_datetime = datetime.datetime.now()\n",
    "# transcript_data_path = f\"data/transcript_data_{str(current_datetime)}.csv\"\n",
    "# pd.DataFrame(export_data).to_csv(transcript_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BInVGdest2uN"
   },
   "outputs": [],
   "source": [
    "transcript_data = pd.read_csv('data/transcript_data_v1.csv') # Using once data has been downloaded\n",
    "#transcript_data = pd.read_csv(transcript_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "0dd8b00724a943a5b431daaf32f7daba",
      "5689293615de458a85c15fe8a41dfe6f",
      "dbbaeacf0c234637be5236a97f0867c6",
      "2fb4fc0db5214275ae275d74ebe58450",
      "c5e2747bf4b0472ca2a43b168142860c",
      "ee3d103601464864ad3eae9abccdde5b",
      "13b3785b21a3486c862281567c5e8625",
      "4620523468804191a8e74f4b03605bb0",
      "2eb20717fc3247ef86e9e295c70c1b53",
      "4fbc34379cec439988dfc7904fbedf33",
      "8110bc3fd38a4f51b72d66ce7fc196c1"
     ]
    },
    "id": "ZiRl2qN0ZVzR",
    "outputId": "e9b46b3f-87cf-47fe-a5ea-61d8d56f1d64"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/18603270/progress-indicator-during-pandas-operations\n",
    "# Transcript download\n",
    "!pip install tqdm --quiet\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Function to get transcript for a given video_id\n",
    "def get_transcript(video_id):\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        return ' '.join([entry['text'] for entry in transcript])\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# # Apply the function to create a new 'transcript' column\n",
    "# transcript_data['transcript'] = transcript_data['video_id'].progress_apply(get_transcript) # lengthy operation so we want to see the progress\n",
    "# transcript_data.to_csv(transcript_data_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-AaQllFokr0-"
   },
   "outputs": [],
   "source": [
    "#transcript_data.to_csv('data/transcript_data_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_data = pd.read_csv('data/transcript_data_v1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_data = transcript_data.replace(to_replace='none', value=np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TKIjefGHZhAQ"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Lowercasing\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Removing punctuation and special characters\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "    # Removing numbers\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "\n",
    "    # Removing stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if not word in stop_words]\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Applying the cleaning text function to all the text columns for analysis in our data\n",
    "transcript_data[['transcript']] = transcript_data[['transcript']].apply(lambda x: x.map(clean_text))\n",
    "transcript_data.isnull().sum()\n",
    "transcript_data = transcript_data.dropna(subset=['transcript']) # Since this is the primary column of interest, null values are not acceptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "991e0af3429b4a85a3b992d88e5f3470",
      "b252934c7e1c4e3caf90b307af043902",
      "68cdea3d7fa6469f86fc059bdb1eeb7f",
      "4929932088e745d6a408fdb31e1f4686",
      "967310f26cf446bfab2ec7934ef96e3d",
      "642afb10663f4adfa57a0373e70cc39e",
      "4c969133f41d407abb34adf24e1edab5",
      "3734dc39ee884461982a5ab6de402994",
      "828ce884d3724495aba5b2392f2b72e3",
      "1cfbed85a9d5479a996f95bb34a3ce90",
      "fc2a89e3ccf14fa789f37a6b349f72c3"
     ]
    },
    "id": "MQzzmef0bJDc",
    "outputId": "ef664eff-1588-473b-e4c3-599cb303f912"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba6a4baba6cf45d0bc42d0397113068a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6588 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "lexicon = empath.Empath()\n",
    "\n",
    "def analyze_vader(text):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    return analyzer.polarity_scores(text)['compound']\n",
    "\n",
    "transcript_data['transcript_vader'] = transcript_data['transcript'].progress_apply(analyze_vader)\n",
    "\n",
    "\n",
    "# Extract sentiment labels using the quantitative metrics\n",
    "transcript_data['vader_category'] = transcript_data['transcript_vader'].apply(lambda x: 'positive' if x > 0 else 'negative' if x < 0 else 'neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VXdhgHZqjoq0",
    "outputId": "277cb933-b332-4ce6-ab46-d380bc013ee1"
   },
   "outputs": [],
   "source": [
    "sns.countplot(data=transcript_data, x='channel_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained earlier, there is a class imbalance in the data, with more transcripts avaialble for Fox news hence we use the F-1 score to evaluate the performance as compared to the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "z91qLJX3bzS-",
    "outputId": "8814d38a-af4e-4015-8d2d-d69d48b4a858"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.histplot(data=transcript_data, x='transcript_vader', hue='channel_name', stat = 'percent')\n",
    "plt.title('Distribution of vader scores for each channel')\n",
    "plt.xlabel('Vader Score')\n",
    "plt.ylabel('Percentage Occurence')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ugzaAUDblyoN",
    "outputId": "d676dd3f-4b27-45be-dd4c-9a6834b5770e"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=transcript_data, x='vader_category', hue='channel_name')\n",
    "plt.title('Distribution of vader category for each channel')\n",
    "plt.xlabel('Vader Category')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring the performance of various classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tt-MYEHMccwa"
   },
   "source": [
    "Classifying the video based on it's transcript into two channels (CNN, Fox News)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "InyyI04VcjkO",
    "outputId": "802090e2-082c-40cb-9c06-5623a4019e36"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import autokeras as ak\n",
    "\n",
    "classification_channel_data = transcript_data[['channel_name','transcript']]\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    tokens = [word for word in tokens if word.lower() not in stopwords.words('english')]  # Remove stopwords\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Lemmatization\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to the text column\n",
    "classification_channel_data['clean_transcript'] = classification_channel_data['transcript'].apply(preprocess_text)\n",
    "#virality_from_title['clean_title'] = virality_from_title['transcript'].apply(preprocess_text)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(classification_channel_data['transcript'], classification_channel_data['channel_name'], test_size=0.2, random_state=42)\n",
    "\n",
    "x_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "clf = ak.TextClassifier(\n",
    "    overwrite=True, max_trials=1\n",
    ")  \n",
    "clf.fit(x_train, y_train, epochs=5)\n",
    "predicted_y = clf.predict(x_test)\n",
    "print(clf.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "predictions = clf.predict(x_test)\n",
    "cm = confusion_matrix(y_test, predictions, labels=['CNN','Fox News'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=['CNN','Fox News'])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_autokeras = f1_score(y_test, predictions, pos_label = 'CNN')\n",
    "print(\"F1 Score for AutoKeras:\", f1_autokeras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/26826002/adding-words-to-stop-words-list-in-tfidfvectorizer-in-sklearn\n",
    "\n",
    "# Starting with Linear Kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "my_additional_stop_words = {'fox','cnn'} # Removing these words to remove any identification and avoid bias\n",
    "stop_words = text.ENGLISH_STOP_WORDS\n",
    "stop_words = stop_words.union(my_additional_stop_words)\n",
    "stop_words = list(stop_words)\n",
    "linear_vectorizer = TfidfVectorizer(stop_words=stop_words, min_df=0.05, max_df=0.9)\n",
    "X = linear_vectorizer.fit_transform(transcript_data['transcript'])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, transcript_data['channel_name'], test_size=0.2, random_state=42)\n",
    "\n",
    "classifier_linear = SVC(kernel='linear')\n",
    "classifier_linear.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predictions = classifier_linear.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions, labels=['CNN','Fox News'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=['CNN','Fox News'])\n",
    "disp.plot()\n",
    "plt.title('Confusion Matrix for Linear Kernel SVM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_linear_svc = f1_score(y_test, predictions, pos_label = 'CNN')\n",
    "print(\"F1 Score for SVC (linear):\", f1_linear_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Polynomial kernel\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=stop_words, min_df=0.05, max_df=0.9)\n",
    "X = vectorizer.fit_transform(transcript_data['transcript'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, transcript_data['channel_name'], test_size=0.2, random_state=42)\n",
    "\n",
    "classifier = SVC(kernel='poly')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions, labels=['CNN','Fox News'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=['CNN','Fox News'])\n",
    "disp.plot()\n",
    "plt.title('Confusion Matrix for Polynomial Kernel SVM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_poly_svc = f1_score(y_test, predictions, pos_label = 'CNN')\n",
    "print(\"F1 Score for SVC (polynomial):\", f1_poly_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using rbf kernel\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=stop_words, min_df=0.05, max_df=0.9)\n",
    "X = vectorizer.fit_transform(transcript_data['transcript'])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, transcript_data['channel_name'], test_size=0.2, random_state=42)\n",
    "\n",
    "classifier = SVC(kernel='rbf')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions, labels=['CNN','Fox News'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=['CNN','Fox News'])\n",
    "disp.plot()\n",
    "plt.title('Confusion Matrix for RBF Kernel SVM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_rbf_svc = f1_score(y_test, predictions, pos_label = 'CNN')\n",
    "print(\"F1 Score for SVC (rbf):\", f1_rbf_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'Model': ['AutoKeras', 'SVC (linear)', 'SVC (Polynomial)','SVC (rbf)'], 'F1 Score': [f1_autokeras, f1_linear_svc, f1_poly_svc,f1_rbf_svc]})\n",
    "\n",
    "# Plotting using Seaborn\n",
    "plt.figure(figsize=(10, 6))  # Adjust size if necessary\n",
    "sns.barplot(x='Model', y='F1 Score', data=data, palette=\"Blues_d\")\n",
    "plt.title('F1 Scores of Different Models')\n",
    "plt.ylim(0, 1)  # Set the y-axis limits to better visualize F1 scores\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xlabel('Model')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)  # Add horizontal grid lines\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that the `AutoKeras` model was the best performing, with the other `SVC` kernels having similar performance, subject to sampling error and average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_data.to_csv('data/transcript_data_v1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing the presence of common words in the transcript of both the channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names (tokens)\n",
    "feature_names = linear_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert the coefficients to a dense NumPy array\n",
    "coefficients_dense = classifier_linear.coef_[0].toarray()\n",
    "\n",
    "# Convert the dense NumPy array to a normal list\n",
    "coefficients = coefficients_dense.tolist()\n",
    "feature_coeff_mapping = {}\n",
    "\n",
    "for i in range(len(feature_names)):\n",
    "    feature_coeff_mapping[feature_names[i]] = coefficients[0][i]\n",
    "\n",
    "# Sort the features by their weight (coefficient)\n",
    "sorted_features = sorted(feature_coeff_mapping.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Extract top features for CNN-like and Fox-like\n",
    "top_features_fox = sorted_features[:10]\n",
    "top_features_cnn = sorted_features[-10:]\n",
    "\n",
    "print(top_features_cnn)\n",
    "print(top_features_fox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting words and weights\n",
    "words1, weights1 = zip(*top_features_cnn)\n",
    "words2, weights2 = zip(*top_features_fox)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.barh(words1, weights1, color='blue', label='CNN-like')\n",
    "plt.barh(words2, weights2, color='red', label='Fox-like')\n",
    "\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Word')\n",
    "plt.title('Word Weights')\n",
    "plt.legend()\n",
    "\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have highest weights on top\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion - While we don't find any noticeable trends that differentiate the word clouds and looking at the frequency of words formed from the transcripts of the two news channels, the classifier giving us a high f-1 score tells us that when trained on a reasonably large dataset, the machine learning techniques can distinguish between the content of the two channels and I find this very interesting and just the start of this particular field of research of inducing polarity and a style of reporting across channels."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0dd8b00724a943a5b431daaf32f7daba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5689293615de458a85c15fe8a41dfe6f",
       "IPY_MODEL_dbbaeacf0c234637be5236a97f0867c6",
       "IPY_MODEL_2fb4fc0db5214275ae275d74ebe58450"
      ],
      "layout": "IPY_MODEL_c5e2747bf4b0472ca2a43b168142860c"
     }
    },
    "13b3785b21a3486c862281567c5e8625": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1cfbed85a9d5479a996f95bb34a3ce90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2eb20717fc3247ef86e9e295c70c1b53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2fb4fc0db5214275ae275d74ebe58450": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4fbc34379cec439988dfc7904fbedf33",
      "placeholder": "​",
      "style": "IPY_MODEL_8110bc3fd38a4f51b72d66ce7fc196c1",
      "value": " 80/80 [00:51&lt;00:00,  1.70it/s]"
     }
    },
    "3734dc39ee884461982a5ab6de402994": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4620523468804191a8e74f4b03605bb0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4929932088e745d6a408fdb31e1f4686": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1cfbed85a9d5479a996f95bb34a3ce90",
      "placeholder": "​",
      "style": "IPY_MODEL_fc2a89e3ccf14fa789f37a6b349f72c3",
      "value": " 80/80 [00:02&lt;00:00, 30.17it/s]"
     }
    },
    "4c969133f41d407abb34adf24e1edab5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4fbc34379cec439988dfc7904fbedf33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5689293615de458a85c15fe8a41dfe6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee3d103601464864ad3eae9abccdde5b",
      "placeholder": "​",
      "style": "IPY_MODEL_13b3785b21a3486c862281567c5e8625",
      "value": "100%"
     }
    },
    "642afb10663f4adfa57a0373e70cc39e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68cdea3d7fa6469f86fc059bdb1eeb7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3734dc39ee884461982a5ab6de402994",
      "max": 80,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_828ce884d3724495aba5b2392f2b72e3",
      "value": 80
     }
    },
    "8110bc3fd38a4f51b72d66ce7fc196c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "828ce884d3724495aba5b2392f2b72e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "967310f26cf446bfab2ec7934ef96e3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "991e0af3429b4a85a3b992d88e5f3470": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b252934c7e1c4e3caf90b307af043902",
       "IPY_MODEL_68cdea3d7fa6469f86fc059bdb1eeb7f",
       "IPY_MODEL_4929932088e745d6a408fdb31e1f4686"
      ],
      "layout": "IPY_MODEL_967310f26cf446bfab2ec7934ef96e3d"
     }
    },
    "b252934c7e1c4e3caf90b307af043902": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_642afb10663f4adfa57a0373e70cc39e",
      "placeholder": "​",
      "style": "IPY_MODEL_4c969133f41d407abb34adf24e1edab5",
      "value": "100%"
     }
    },
    "c5e2747bf4b0472ca2a43b168142860c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbbaeacf0c234637be5236a97f0867c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4620523468804191a8e74f4b03605bb0",
      "max": 80,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2eb20717fc3247ef86e9e295c70c1b53",
      "value": 80
     }
    },
    "ee3d103601464864ad3eae9abccdde5b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc2a89e3ccf14fa789f37a6b349f72c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
